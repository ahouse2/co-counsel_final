version: '3.9'

services:
  # Frontend service
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "5173:5173"
    environment:
      - VITE_API_BASE_URL=http://localhost:8000
    depends_on:
      - api
    networks:
      - app-network

  # Backend API service
  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - MODEL_PROVIDERS_PRIMARY=gemini
      - MODEL_PROVIDERS_SECONDARY=openai
      - DEFAULT_CHAT_MODEL=gemini-2.5-flash
      - DEFAULT_EMBEDDING_MODEL=text-embedding-004
      - DEFAULT_VISION_MODEL=gemini-2.5-flash
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=securepassword
      - QDRANT_URL=http://qdrant:6333
      - VECTOR_DIR=/data/vector
      - VOICE_SESSIONS_DIR=/data/voice/sessions
      - VOICE_CACHE_DIR=/models
      - DOCUMENT_STORAGE_PATH=/var/cocounsel/documents
      - GRAPH_SNAPSHOT_PATH=/var/cocounsel/graphs
      - TELEMETRY_BUFFER_PATH=/var/cocounsel/telemetry
      - BILLING_USAGE_PATH=/data/billing/usage.json
      - BILLING_DEFAULT_PLAN=community
      - TELEMETRY_ENABLED=false
      - TELEMETRY_OTLP_ENDPOINT=http://otel-collector:4317
      - TELEMETRY_OTLP_INSECURE=true
      - TELEMETRY_ENVIRONMENT=community
      - STT_SERVICE_URL=http://stt:9000
      - TTS_SERVICE_URL=http://tts:5002
      - HUGGINGFACE_HUB_CACHE=/var/cocounsel/models/huggingface
      - WHISPER_MODEL_PATH=/var/cocounsel/models/whisper
      - TTS_MODEL_PATH=/var/cocounsel/models/tts
    depends_on:
      - neo4j
      - qdrant
    networks:
      - app-network
    volumes:
      - api_data:/data
      - voice_models:/models
      - ./var/storage/documents:/var/cocounsel/documents
      - ./var/storage/graphs:/var/cocounsel/graphs
      - ./var/storage/telemetry:/var/cocounsel/telemetry
      - ./var/models/huggingface:/var/cocounsel/models/huggingface
      - ./var/models/whisper:/var/cocounsel/models/whisper
      - ./var/models/tts:/var/cocounsel/models/tts

  # Neo4j database
  neo4j:
    image: neo4j:5.20
    environment:
      - NEO4J_AUTH=neo4j/securepassword
      - NEO4J_dbms_memory_heap_initial__size=1G
      - NEO4J_dbms_memory_heap_max__size=2G
      - NEO4J_dbms_security_auth__enabled=true
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
      - ./infra/migrations/neo4j:/var/lib/neo4j/migrations:ro
    networks:
      - app-network

  # Qdrant vector database
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - app-network

  # Speech-to-text service
  stt:
    image: ghcr.io/guillaumekln/faster-whisper-server:latest
    environment:
      - ASR_MODEL=openai/whisper-small
      - ASR_ENGINE=faster_whisper
      - ASR_BEAM_SIZE=5
      - ASR_DEVICE=cpu
      - HUGGINGFACE_HUB_CACHE=/models/huggingface
      - ASR_OUTPUT_LANGUAGE=en
    ports:
      - "9000:9000"
    volumes:
      - ./var/models/huggingface:/models/huggingface
      - ./var/models/whisper:/models/whisper
    networks:
      - app-network

  # Text-to-speech service
  tts:
    image: rhasspy/larynx:latest
    environment:
      - LARYNX_VOICE=en-us-blizzard_lessac
      - LARYNX_OUTPUT_DIR=/output
      - HUGGINGFACE_HUB_CACHE=/models/huggingface
    ports:
      - "5002:5002"
    volumes:
      - ./var/models/huggingface:/models/huggingface
      - ./var/models/tts:/models/tts
      - ./var/audio:/output
    networks:
      - app-network

volumes:
  neo4j_data:
  qdrant_data:
  api_data:
  voice_models:

networks:
  app-network:
    driver: bridgeversion: '3.9'

services:
  # Frontend service
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "5173:5173"
    environment:
      - VITE_API_BASE_URL=http://localhost:8000
    depends_on:
      - api
    networks:
      - app-network

  # Backend API service
  api:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - MODEL_PROVIDERS_PRIMARY=gemini
      - MODEL_PROVIDERS_SECONDARY=openai
      - DEFAULT_CHAT_MODEL=gemini-2.5-flash
      - DEFAULT_EMBEDDING_MODEL=text-embedding-004
      - DEFAULT_VISION_MODEL=gemini-2.5-flash
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=securepassword
      - QDRANT_URL=http://qdrant:6333
      - VECTOR_DIR=/data/vector
      - VOICE_SESSIONS_DIR=/data/voice/sessions
      - VOICE_CACHE_DIR=/models
      - DOCUMENT_STORAGE_PATH=/var/cocounsel/documents
      - GRAPH_SNAPSHOT_PATH=/var/cocounsel/graphs
      - TELEMETRY_BUFFER_PATH=/var/cocounsel/telemetry
      - BILLING_USAGE_PATH=/data/billing/usage.json
      - BILLING_DEFAULT_PLAN=community
      - TELEMETRY_ENABLED=false
      - TELEMETRY_OTLP_ENDPOINT=http://otel-collector:4317
      - TELEMETRY_OTLP_INSECURE=true
      - TELEMETRY_ENVIRONMENT=community
      - STT_SERVICE_URL=http://stt:9000
      - TTS_SERVICE_URL=http://tts:5002
      - HUGGINGFACE_HUB_CACHE=/var/cocounsel/models/huggingface
      - WHISPER_MODEL_PATH=/var/cocounsel/models/whisper
      - TTS_MODEL_PATH=/var/cocounsel/models/tts
    depends_on:
      - neo4j
      - qdrant
    networks:
      - app-network
    volumes:
      - api_data:/data
      - voice_models:/models
      - ./var/storage/documents:/var/cocounsel/documents
      - ./var/storage/graphs:/var/cocounsel/graphs
      - ./var/storage/telemetry:/var/cocounsel/telemetry
      - ./var/models/huggingface:/var/cocounsel/models/huggingface
      - ./var/models/whisper:/var/cocounsel/models/whisper
      - ./var/models/tts:/var/cocounsel/models/tts

  # Neo4j database
  neo4j:
    image: neo4j:5.20
    environment:
      - NEO4J_AUTH=neo4j/securepassword
      - NEO4J_dbms_memory_heap_initial__size=1G
      - NEO4J_dbms_memory_heap_max__size=2G
      - NEO4J_dbms_security_auth__enabled=true
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
      - ./infra/migrations/neo4j:/var/lib/neo4j/migrations:ro
    networks:
      - app-network

  # Qdrant vector database
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - app-network

  # Speech-to-text service
  stt:
    image: ghcr.io/guillaumekln/faster-whisper-server:latest
    environment:
      - ASR_MODEL=openai/whisper-small
      - ASR_ENGINE=faster_whisper
      - ASR_BEAM_SIZE=5
      - ASR_DEVICE=cpu
      - HUGGINGFACE_HUB_CACHE=/models/huggingface
      - ASR_OUTPUT_LANGUAGE=en
    ports:
      - "9000:9000"
    volumes:
      - ./var/models/huggingface:/models/huggingface
      - ./var/models/whisper:/models/whisper
    networks:
      - app-network

  # Text-to-speech service
  tts:
    image: rhasspy/larynx:latest
    environment:
      - LARYNX_VOICE=en-us-blizzard_lessac
      - LARYNX_OUTPUT_DIR=/output
      - HUGGINGFACE_HUB_CACHE=/models/huggingface
    ports:
      - "5002:5002"
    volumes:
      - ./var/models/huggingface:/models/huggingface
      - ./var/models/tts:/models/tts
      - ./var/audio:/output
    networks:
      - app-network

volumes:
  neo4j_data:
  qdrant_data:
  api_data:
  voice_models:

networks:
  app-network:
    driver: bridge